{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "24b19fff-8f42-4e9f-a73e-00cff106805a",
      "metadata": {
        "id": "24b19fff-8f42-4e9f-a73e-00cff106805a"
      },
      "source": [
        "# M-Shots Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34723a72-1601-4685-a0ba-bff544425d48",
      "metadata": {
        "id": "34723a72-1601-4685-a0ba-bff544425d48"
      },
      "source": [
        "In this notebook, we'll explore small prompt engineering techniques and recommendations that will help us elicit responses from the models that are better suited to our needs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "249ufmYTdvOa",
        "outputId": "6fcc4af6-f8d6-468f-8ebe-e6ec1a9d8877"
      },
      "id": "249ufmYTdvOa",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/325.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/325.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m317.4/325.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: python-dotenv, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.34.0 python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())"
      ],
      "metadata": {
        "id": "27c3yDJWdnsb"
      },
      "id": "27c3yDJWdnsb",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('IronAPI')"
      ],
      "metadata": {
        "id": "bfmkIXfDegmQ"
      },
      "id": "bfmkIXfDegmQ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "502cfc93-21e0-498f-9650-37bc6ddd514d",
      "metadata": {
        "id": "502cfc93-21e0-498f-9650-37bc6ddd514d"
      },
      "source": [
        "# Formatting the answer with Few Shot Samples.\n",
        "\n",
        "To obtain the model's response in a specific format, we have various options, but one of the most convenient is to use Few-Shot Samples. This involves presenting the model with pairs of user queries and example responses.\n",
        "\n",
        "Large models like GPT-3.5 respond well to the examples provided, adapting their response to the specified format.\n",
        "\n",
        "Depending on the number of examples given, this technique can be referred to as:\n",
        "* Zero-Shot.\n",
        "* One-Shot.\n",
        "* Few-Shots.\n",
        "\n",
        "With One Shot should be enough, and it is recommended to use a maximum of six shots. It's important to remember that this information is passed in each query and occupies space in the input prompt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a8344712-06d7-4c24-83d8-f36d62926e5e",
      "metadata": {
        "id": "a8344712-06d7-4c24-83d8-f36d62926e5e"
      },
      "outputs": [],
      "source": [
        "# Function to call the model.\n",
        "def return_OAIResponse(user_message, context):\n",
        "    client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=OPENAI_API_KEY,\n",
        ")\n",
        "\n",
        "    newcontext = context.copy()\n",
        "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=newcontext,\n",
        "            temperature=1,\n",
        "        )\n",
        "\n",
        "    return (response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f611d73d-9330-466d-b705-543667e1b561",
      "metadata": {
        "id": "f611d73d-9330-466d-b705-543667e1b561"
      },
      "source": [
        "In this zero-shots prompt we obtain a correct response, but without formatting, as the model incorporates the information he wants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
        "outputId": "49aacd64-fb0d-4699-ee16-40e2df3ea0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebastian Vettel won the F1 World Championship in 2010. He was driving for the Red Bull Racing team.\n"
          ]
        }
      ],
      "source": [
        "#zero-shot\n",
        "context_user = [\n",
        "    {'role':'system', 'content':'You are an expert in F1.'}\n",
        "]\n",
        "print(return_OAIResponse(\"Who won the F1 2010?\", context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8",
      "metadata": {
        "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8"
      },
      "source": [
        "For a model as large and good as GPT 3.5, a single shot is enough to learn the output format we expect.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
        "outputId": "6c8854c1-ac35-4b55-8181-e6d0bb981149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driver: Sebastian Vettel.\n",
            "Team: Red Bull Racing.\n"
          ]
        }
      ],
      "source": [
        "#one-shot\n",
        "context_user = [\n",
        "    {'role':'system', 'content':\n",
        "     \"\"\"You are an expert in F1.\n",
        "\n",
        "     Who won the 2000 f1 championship?\n",
        "     Driver: Michael Schumacher.\n",
        "     Team: Ferrari.\"\"\"}\n",
        "]\n",
        "print(return_OAIResponse(\"Who won the F1 2011?\", context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32c454a8-181b-482b-873a-81d6ffde4674",
      "metadata": {
        "id": "32c454a8-181b-482b-873a-81d6ffde4674"
      },
      "source": [
        "Smaller models, or more complicated formats, may require more than one shot. Here a sample with two shots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
        "outputId": "ad9200b8-709d-49c1-d516-84b9251ccbe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 2006 F1 championship was won by Fernando Alonso, driving for Renault.\n"
          ]
        }
      ],
      "source": [
        "#Few shots\n",
        "context_user = [\n",
        "    {'role':'system', 'content':\n",
        "     \"\"\"You are an expert in F1.\n",
        "\n",
        "     Who won the 2010 f1 championship?\n",
        "     Driver: Sebastian Vettel.\n",
        "     Team: Red Bull Renault.\n",
        "\n",
        "     Who won the 2009 f1 championship?\n",
        "     Driver: Jenson Button.\n",
        "     Team: BrawnGP.\"\"\"}\n",
        "]\n",
        "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
        "outputId": "38f383ca-73d5-48cf-8d98-443f4915eae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 2019 F1 Championship was won by Lewis Hamilton driving for Mercedes.\n"
          ]
        }
      ],
      "source": [
        "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86",
      "metadata": {
        "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86"
      },
      "source": [
        "We've been creating the prompt without using OpenAI's roles, and as we've seen, it worked correctly.\n",
        "\n",
        "However, the proper way to do this is by using these roles to construct the prompt, making the model's learning process even more effective.\n",
        "\n",
        "By not feeding it the entire prompt as if they were system commands, we enable the model to learn from a conversation, which is more realistic for it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
        "outputId": "302d10a3-4a8a-4afb-9a1d-9f110c93f6ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driver: Lewis Hamilton. \n",
            "Team: Mercedes. \n",
            "Points: 413.\n"
          ]
        }
      ],
      "source": [
        "#Recomended solution\n",
        "context_user = [\n",
        "    {'role':'system', 'content':'You are and expert in f1.\\n\\n'},\n",
        "    {'role':'user', 'content':'Who won the 2010 f1 championship?'},\n",
        "    {'role':'assistant', 'content':\"\"\"Driver: Sebastian Vettel. \\nTeam: Red Bull. \\nPoints: 256. \"\"\"},\n",
        "    {'role':'user', 'content':'Who won the 2009 f1 championship?'},\n",
        "    {'role':'assistant', 'content':\"\"\"Driver: Jenson Button. \\nTeam: BrawnGP. \\nPoints: 95. \"\"\"},\n",
        "]\n",
        "\n",
        "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac6f6b42-f351-496b-a7e8-1286426457eb",
      "metadata": {
        "id": "ac6f6b42-f351-496b-a7e8-1286426457eb"
      },
      "source": [
        "We could also address it by using a more conventional prompt, describing what we want and how we want the format.\n",
        "\n",
        "However, it's essential to understand that in this case, the model is following instructions, whereas in the case of use shots, it is learning in real-time during inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
        "outputId": "cac42fdb-e75d-42ba-9fe8-daa361baf2d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driver: Lewis Hamilton\n",
            "Team: Mercedes\n",
            "Points: 413\n"
          ]
        }
      ],
      "source": [
        "context_user = [\n",
        "    {'role':'system', 'content':\"\"\"You are and expert in f1.\n",
        "    You are going to answer the question of the user giving the name of the rider,\n",
        "    the name of the team and the points of the champion, following the format:\n",
        "    Drive:\n",
        "    Team:\n",
        "    Points: \"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "KNDL1GzVngyL",
      "metadata": {
        "id": "KNDL1GzVngyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16026d30-8884-4cc3-ce2a-a33b6a67cc26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driver: Fernando Alonso.\n",
            "Team: Renault.\n"
          ]
        }
      ],
      "source": [
        "context_user = [\n",
        "    {'role':'system', 'content':\n",
        "     \"\"\"You are classifying .\n",
        "\n",
        "     Who won the 2010 f1 championship?\n",
        "     Driver: Sebastian Vettel.\n",
        "     Team: Red Bull Renault.\n",
        "\n",
        "     Who won the 2009 f1 championship?\n",
        "     Driver: Jenson Button.\n",
        "     Team: BrawnGP.\"\"\"}\n",
        "]\n",
        "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qZPNTLMPnkQ4",
      "metadata": {
        "id": "qZPNTLMPnkQ4"
      },
      "source": [
        "Few Shots for classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ejcstgTxnnX5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejcstgTxnnX5",
        "outputId": "a711819d-5bc4-4931-f650-96beffb29eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: Neutral\n"
          ]
        }
      ],
      "source": [
        "context_user = [\n",
        "    {'role':'system', 'content':\n",
        "     \"\"\"You are an expert in reviewing product opinions and classifying them as positive or negative.\n",
        "\n",
        "     It fulfilled its function perfectly, I think the price is fair, I would buy it again.\n",
        "     Sentiment: Positive\n",
        "\n",
        "     It didn't work bad, but I wouldn't buy it again, maybe it's a bit expensive for what it does.\n",
        "     Sentiment: Negative.\n",
        "\n",
        "     I wouldn't know what to say, my son uses it, but he doesn't love it.\n",
        "     Sentiment: Neutral\n",
        "     \"\"\"}\n",
        "]\n",
        "print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffe1d50b-d262-4e74-8f2d-3559f3fcfb15",
      "metadata": {
        "id": "ffe1d50b-d262-4e74-8f2d-3559f3fcfb15"
      },
      "source": [
        "# Exercise\n",
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try at least 3 versions\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
        " - What did you learn?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9adda59c-ad09-4e9d-88cd-54f42384a5f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9adda59c-ad09-4e9d-88cd-54f42384a5f3",
        "outputId": "05b81a6c-ca3c-49a0-a29d-a0ca6ace8f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm unable to provide real-time updates on specific stock performance, as it can fluctuate frequently. I recommend checking financial news sources or stock market websites for the latest information on the best-performing stock in 2024.\n"
          ]
        }
      ],
      "source": [
        "#Recomended solution\n",
        "context_user = [\n",
        "    {'role':'system', 'content':'You are and expert in stock markets.\\n\\n'},\n",
        "    {'role':'user', 'content':'What was the best performing stock in 2023?'},\n",
        "    {'role':'assistant', 'content':\"\"\"Stock: Coinbase. \\nFounded: 2012. \\nCEO: Brian Armstrong. \"\"\"},\n",
        "    {'role':'user', 'content':'What was the best performing stock in 2022?'},\n",
        "    {'role':'assistant', 'content':\"\"\"Stock: Occidental Petroleum. \\nFounded: 1920. \\nCEO: Vicki Hollub. \"\"\"},\n",
        "]\n",
        "\n",
        "print(return_OAIResponse(\"What is the best performing stock in 2024?\", context_user))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(return_OAIResponse(\"What was the best performing stock in 2021?\", context_user))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQsUPazxh4NQ",
        "outputId": "b0de5a7f-aed5-4c9d-bff1-7130558ce21b"
      },
      "id": "hQsUPazxh4NQ",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock: Moderna Inc. \n",
            "Founded: 2010. \n",
            "CEO: Stéphane Bancel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_user = [\n",
        "    {'role':'system', 'content':\n",
        "     \"\"\"You are an expert historian.\n",
        "\n",
        "     When was slavery abolished in Russia?\n",
        "     Year: 1723.\n",
        "     Decision made by: Peter the Great.\n",
        "\n",
        "     When was slavery abolished in Germany?\n",
        "     Year: 1837.\n",
        "     Decision made by: German Parliament.\"\"\"}\n",
        "]\n",
        "print(return_OAIResponse(\"When was slavery abolished in the US?\", context_user))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zO8YQUUiilW",
        "outputId": "e5008071-9c60-406c-8502-920e4414d636"
      },
      "id": "3zO8YQUUiilW",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slavery was officially abolished in the United States with the ratification of the 13th Amendment to the Constitution on December 6, 1865, following the end of the American Civil War.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_user = [\n",
        "    {'role':'system', 'content':\n",
        "     \"\"\"You are an expert historian. Provide your answer in the following format\n",
        "\n",
        "     When was slavery abolished in Russia?\n",
        "     Year: 1723.\n",
        "     Decision made by: Peter the Great.\n",
        "\n",
        "     When was slavery abolished in Germany?\n",
        "     Year: 1837.\n",
        "     Decision made by: German Parliament.\"\"\"}\n",
        "]\n",
        "print(return_OAIResponse(\"When was slavery abolished in the US?\", context_user))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO1Yks-2j41Z",
        "outputId": "c0716127-9bdc-4d5e-9e73-1c4f5a620526"
      },
      "id": "PO1Yks-2j41Z",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When was slavery abolished in the US?\n",
            "Year: 1865. \n",
            "Decision made by: The 13th Amendment to the United States Constitution, which was passed by Congress on January 31, 1865, and ratified on December 6, 1865.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_user = [\n",
        "    {'role':'system', 'content':\n",
        "     \"\"\"You are an expert historian. Provide your answer in the following format, stipulate only two pieces of information the year and the decision-making body without any further information\n",
        "\n",
        "     When was slavery abolished in Russia?\n",
        "     Year: 1723.\n",
        "     Decision-making body: Tsar Peter the Great.\n",
        "\n",
        "     When was slavery abolished in Germany?\n",
        "     Year: 1837.\n",
        "     Decision-making body: German Parliament.\"\"\"}\n",
        "]\n",
        "print(return_OAIResponse(\"When was slavery abolished in the US?\", context_user))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9V8mlJLjomE",
        "outputId": "5c3f9bcb-0d58-4ffb-e5b3-b2569da314f4"
      },
      "id": "S9V8mlJLjomE",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Year: 1865.  \n",
            "Decision-making body: US Congress.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Recomended solution\n",
        "context_user = [\n",
        "    {'role':'system', 'content':'You are and expert in non-cooperative game theory.\\n\\n'},\n",
        "    {'role':'user', 'content':'What are pure strategy Nash equilibria in the prisoners dilemma game?'},\n",
        "    {'role':'assistant', 'content':\"\"\"List of Nash equilibria: (Confess, Confess).\"\"\"},\n",
        "    {'role':'user', 'content':'What are pure strategy Nash equilibria in the stag hunt game?'},\n",
        "    {'role':'assistant', 'content':\"\"\"List of Nash equilibria: (Stag, Stag), (Hare, Hare). \"\"\"},\n",
        "]\n",
        "\n",
        "print(return_OAIResponse(\"What are pure strategy Nash equilibria in the chicken game?\", context_user))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQre4YDrlRi8",
        "outputId": "eb07ad7b-1566-4379-c812-4304a7a43d3b"
      },
      "id": "QQre4YDrlRi8",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the chicken game, the pure strategy Nash equilibria are (Swerve, Straight) and (Straight, Swerve).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Recomended solution\n",
        "context_user = [\n",
        "    {'role':'system', 'content':'You are and expert in non-cooperative game theory.\\n\\n'},\n",
        "    {'role':'user', 'content':'What are pure strategy Nash equilibria in the prisoners dilemma game?'},\n",
        "    {'role':'assistant', 'content':\"\"\"List of Nash equilibria: (Confess, Confess).\"\"\"},\n",
        "    {'role':'user', 'content':'What are pure strategy Nash equilibria in the stag hunt game?'},\n",
        "    {'role':'assistant', 'content':\"\"\"List of Nash equilibria: (Stag, Stag), (Hare, Hare). \"\"\"},\n",
        "]\n",
        "\n",
        "print(return_OAIResponse(\"What are pure strategy Nash equilibria in this game: \tRaise Limit\tKeep Limit\tDodge, Raise Limit\t(45,55)(50,50)(40,60), Keep Limit (60,40)(55,45)(50,50), Dodge (45,55)(55,45)(40,60)?\", context_user))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsjzrP48mrFY",
        "outputId": "f8da7172-bb95-477b-c22a-37505da74afc"
      },
      "id": "vsjzrP48mrFY",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The pure strategy Nash equilibria in this game are: (Raise Limit, Keep Limit), (Keep Limit, Raise Limit), and (Keep Limit, Keep Limit).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Recomended solution\n",
        "context_user = [\n",
        "    {'role':'system', 'content':'You are and expert in non-cooperative game theory.\\n\\n'},\n",
        "    {'role':'user', 'content':'What are pure strategy Nash equilibria in the prisoners dilemma game: Confess Dont confess, Confess (-6,-6) (0, -10), Dont confess (-10,0) (-1,-1)?'},\n",
        "    {'role':'assistant', 'content':\"\"\"List of Nash equilibria: (Confess, Confess).\"\"\"},\n",
        "    {'role':'user', 'content':'What are pure strategy Nash equilibria in the stag hunt game: Stag Hare, Stag (3,3) (0, 1), Hare (1,0) (1,1)?'},\n",
        "    {'role':'assistant', 'content':\"\"\"List of Nash equilibria: (Stag, Stag), (Hare, Hare). \"\"\"},\n",
        "]\n",
        "\n",
        "print(return_OAIResponse(\"What are pure strategy Nash equilibria in this game: \tRaise Limit\tKeep Limit\tDodge, Raise Limit\t(45,55)(50,50)(40,60), Keep Limit (60,40)(55,45)(50,50), Dodge (45,55)(55,45)(40,60)?\", context_user))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-ZEB_Bao8V9",
        "outputId": "a43b4b4d-37cc-4a62-b01e-a8bdb80f3cdb"
      },
      "id": "x-ZEB_Bao8V9",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The pure strategy Nash equilibria in this game are: (Raise Limit, Keep Limit) and (Keep Limit, Dodge).\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}